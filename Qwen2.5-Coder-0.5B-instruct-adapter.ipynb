{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, AdaLoraConfig, TaskType\n",
    "\n",
    "df = pd.read_json('./dataset/input.json')\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Tokenizer(name_or_path='./Qwen/Qwen2.5-Coder-0.5B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./Qwen/Qwen2.5-Coder-0.5B-Instruct', use_fast=False, trust_remote_code=True)\n",
    "\n",
    "# 数据处理函数\n",
    "def process_func(example):\n",
    "    MAX_LENGTH = 4096    \n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(f\"<|im_start|>system\\n你是一个专业的代码专家，熟悉AJX语言，熟悉高德地图前端开发，熟悉公共交通业务，能够根据高德地图前端开发需求，开发代码。<|im_end|>\\n<|im_start|>user\\n{example['instruction'] }<|im_end|>\\n<|im_start|>assistant\\n\", add_special_tokens=False)  # add_special_tokens 不在开头加 special_tokens\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]  \n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  \n",
    "    if len(input_ids) > MAX_LENGTH: \n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91810d9b8a6849be9daf0ef3e8f3a5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,600,672 || all params: 500,633,608 || trainable%: 1.3185\n"
     ]
    }
   ],
   "source": [
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)\n",
    "\n",
    "# 加载基础模型\n",
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './Qwen/Qwen2.5-Coder-0.5B-Instruct/',\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# 配置AdaLora适配器\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,  # 适配器秩\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    init_r=12,  # 初始秩\n",
    "    target_r=8,  # 目标秩\n",
    "    beta1=0.85,  # AdaLora特有的超参数\n",
    "    beta2=0.85,\n",
    "    tinit=200,  # 预热步数\n",
    "    tfinal=1000,  # 最终步数\n",
    "    deltaT=10,  # 更新频率\n",
    ")\n",
    "\n",
    "# 创建PeftModel\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model.config.use_cache = False\n",
    "\n",
    "# 训练参数配置\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2.5-Coder-0.5B-Instruct-Adapter\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=12,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    gradient_checkpointing=True,\n",
    "    # AdaLora相关的优化器设置\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "# 创建Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb3730730564e5fa810b5d7cd776944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.7043, 'grad_norm': 0.515550434589386, 'learning_rate': 0.0009866666666666667, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.8418, 'grad_norm': 0.5652494430541992, 'learning_rate': 0.0008533333333333334, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3881, 'grad_norm': 0.6480653285980225, 'learning_rate': 0.0007199999999999999, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4133, 'grad_norm': 0.6063621044158936, 'learning_rate': 0.0005866666666666667, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9542, 'grad_norm': 0.6298330426216125, 'learning_rate': 0.0004533333333333333, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4183, 'grad_norm': 0.6259854435920715, 'learning_rate': 0.00032, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.076, 'grad_norm': 0.6271648406982422, 'learning_rate': 0.0001866666666666667, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8914, 'grad_norm': 0.6293167471885681, 'learning_rate': 5.333333333333334e-05, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchengzhuo/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 18814.324, 'train_samples_per_second': 0.054, 'train_steps_per_second': 0.004, 'train_loss': 5.819442703610375, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=84, training_loss=5.819442703610375, metrics={'train_runtime': 18814.324, 'train_samples_per_second': 0.054, 'train_steps_per_second': 0.004, 'total_flos': 1245372634329840.0, 'train_loss': 5.819442703610375, 'epoch': 1.984251968503937})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理部分\n",
    "def generate_response(is_finetune, prompt):\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    from peft import PeftModel\n",
    "    import torch\n",
    "\n",
    "    mode_path = 'Qwen/Qwen2.5-Coder-0.5B-Instruct/'\n",
    "    adapter_path = 'output/Qwen2.5-Coder-0.5B-Instruct-Adapter/checkpoint-84/'\n",
    "\n",
    "    # 加载tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(mode_path, trust_remote_code=True)\n",
    "\n",
    "    # 加载基础模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        mode_path, \n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    ).eval()\n",
    "    if is_finetune:\n",
    "        # 加载adapter权重\n",
    "        model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        [\n",
    "        # {\"role\":\"system\",\"content\":\"你是一个专业的代码专家，熟悉AJX语言，熟悉高德地图前端开发，熟悉公共交通业务，能够根据高德地图前端开发需求，开发代码。\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_dict=True\n",
    "    ).to('mps')\n",
    "\n",
    "    gen_config = {\"max_length\": 4096, \"do_sample\": True, \"top_k\": 1}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **gen_config)\n",
    "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原模型回答：\n",
      " 在高德地图前端公共交通业务中，计算和记录用户在页面上的停留时间并支持暂停/恢复计时功能可以通过以下步骤实现：\n",
      "\n",
      "1. **创建一个计时器**：使用JavaScript创建一个计时器来记录用户停留的时间。\n",
      "\n",
      "2. **监听页面滚动事件**：当用户滚动页面时，更新计时器的值。\n",
      "\n",
      "3. **暂停计时**：当用户暂停滚动时，停止计时器。\n",
      "\n",
      "4. **恢复计时**：当用户恢复滚动时，重新开始计时器。\n",
      "\n",
      "5. **显示计时结果**：在页面上显示用户停留的时间。\n",
      "\n",
      "以下是一个简单的示例代码，展示了如何实现这些功能：\n",
      "\n",
      "```javascript\n",
      "// 创建一个计时器\n",
      "var timer = null;\n",
      "\n",
      "// 计算停留时间\n",
      "function calculateStayTime() {\n",
      "    var startTime = new Date();\n",
      "    var endTime = new Date();\n",
      "    var timeDifference = endTime - startTime;\n",
      "    return timeDifference / 1000; // 将秒转换为毫秒\n",
      "}\n",
      "\n",
      "// 监听页面滚动事件\n",
      "window.addEventListener('scroll', function() {\n",
      "    if (timer) {\n",
      "        clearInterval(timer);\n",
      "    }\n",
      "    timer = setInterval(calculateStayTime, 1000); // 每秒更新一次停留时间\n",
      "});\n",
      "\n",
      "// 暂停计时\n",
      "function pauseTimer() {\n",
      "    if (timer) {\n",
      "        clearInterval(timer);\n",
      "        timer = null;\n",
      "    }\n",
      "}\n",
      "\n",
      "// 恢复计时\n",
      "function resumeTimer() {\n",
      "    if (timer) {\n",
      "        clearInterval(timer);\n",
      "        timer = setInterval(calculateStayTime, 1000); // 每秒更新一次停留时间\n",
      "    }\n",
      "}\n",
      "\n",
      "// 显示计时结果\n",
      "function displayStayTime() {\n",
      "    var stayTime = calculateStayTime();\n",
      "    console.log('停留时间: ' + stayTime + ' 秒');\n",
      "}\n",
      "```\n",
      "\n",
      "### 解释\n",
      "\n",
      "- **calculateStayTime函数**：计算用户停留的时间。它使用`Date`对象来获取当前时间，并计算两个时间之间的差值，然后将其转换为秒。\n",
      "  \n",
      "- **window.addEventListener('scroll', function() {...})**：监听页面滚动事件，当用户滚动时，清除计时器并重新开始计时。\n",
      "\n",
      "- **pauseTimer和resumeTimer函数**：暂停和恢复计时器。当用户暂停滚动时，清除计时器；当用户恢复滚动时，重新开始计时器。\n",
      "\n",
      "- **displayStayTime函数**：显示用户停留的时间。\n",
      "\n",
      "通过这种方式，你可以实现用户在页面上的停留时间的实时记录和暂停/恢复计时功能。\n",
      "adalora微调模型回答：\n",
      " 在高德地图前端公共交通业务中，计算和记录用户在页面上的停留时间并支持暂停/恢复计时功能可以通过以下步骤实现：\n",
      "\n",
      "1. **创建一个计时器**：使用JavaScript创建一个计时器来记录用户停留的时间。\n",
      "\n",
      "2. **监听页面滚动事件**：当用户滚动页面时，更新计时器的值。\n",
      "\n",
      "3. **暂停计时**：当用户暂停滚动时，停止计时器。\n",
      "\n",
      "4. **恢复计时**：当用户恢复滚动时，重新开始计时器。\n",
      "\n",
      "5. **显示计时信息**：在页面上显示用户停留的时间。\n",
      "\n",
      "以下是一个简单的示例代码，展示了如何实现这些功能：\n",
      "\n",
      "```javascript\n",
      "// 创建一个计时器\n",
      "var timer = null;\n",
      "\n",
      "// 计算停留时间\n",
      "function calculateStayTime() {\n",
      "    var startTime = new Date();\n",
      "    var endTime = new Date();\n",
      "    var timeDifference = endTime - startTime;\n",
      "    return timeDifference / 1000; // 将秒转换为毫秒\n",
      "}\n",
      "\n",
      "// 监听页面滚动事件\n",
      "window.addEventListener('scroll', function() {\n",
      "    var currentTime = calculateStayTime();\n",
      "    console.log('停留时间: ' + currentTime + ' 秒');\n",
      "});\n",
      "\n",
      "// 暂停计时\n",
      "function pauseTimer() {\n",
      "    if (timer) {\n",
      "        clearInterval(timer);\n",
      "        timer = null;\n",
      "    }\n",
      "}\n",
      "\n",
      "// 恢复计时\n",
      "function resumeTimer() {\n",
      "    if (!timer) {\n",
      "        timer = setInterval(calculateStayTime, 1000); // 每秒更新一次停留时间\n",
      "    }\n",
      "}\n",
      "\n",
      "// 显示计时信息\n",
      "function displayStayTimeInfo() {\n",
      "    var currentTime = calculateStayTime();\n",
      "    document.getElementById('stay-time-info').innerText = '停留时间: ' + currentTime + ' 秒';\n",
      "}\n",
      "\n",
      "// 初始化计时器\n",
      "displayStayTimeInfo();\n",
      "\n",
      "// 暂停和恢复计时\n",
      "pauseTimer();\n",
      "resumeTimer();\n",
      "```\n",
      "\n",
      "### 解释\n",
      "\n",
      "- **calculateStayTime函数**：计算用户停留的时间。它使用`Date`对象来获取当前时间，并计算两个时间之间的差值。\n",
      "- **window.addEventListener('scroll', function() {...})**：监听页面滚动事件，每次滚动时调用`calculateStayTime`函数更新计时器。\n",
      "- **pauseTimer和resumeTimer函数**：暂停和恢复计时器。如果计时器已经存在，则清除它，否则创建一个新的计时器。\n",
      "- **displayStayTimeInfo函数**：显示用户停留的时间信息到页面上。\n",
      "\n",
      "通过这种方式，你可以实现用户在页面上的停留时间的实时记录和暂停/恢复计时功能。\n"
     ]
    }
   ],
   "source": [
    "# 测试生成\n",
    "test_prompt = \"在高德地图前端公共交通业务中，如何计算和记录用户在页面上的停留时间，并支持暂停/恢复计时功能？\"\n",
    "response1 = generate_response(False, test_prompt)\n",
    "print(\"原模型回答：\\n\",response1)\n",
    "response2 = generate_response(True, test_prompt)\n",
    "print(\"adalora微调模型回答：\\n\",response2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
